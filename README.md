# Multi-layer-perceptron

#MLP 

# It is a NN that consists of interconnected layers 
# Each node in a layer is connected to every node in the previous layer and each node in a layer performs a different function on the input data.
#A MLP consists of a input layer , output layer and hidden layer 
#The hidden layers in the MLP perform transformations on the input data using a non-linear activation function, which helps to model complex relationships between the input and output variables.
#The number of hidden layers and the number of nodes in each layer are hyperparameters that can be tuned to optimize the performance of the MLP.
#the number of hidden layers is often larger than the number of input or output nodes, which allows the MLP to learn more complex representations of the input data.
